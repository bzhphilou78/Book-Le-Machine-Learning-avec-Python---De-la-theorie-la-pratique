{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = datasets.load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ..., 10.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ..., 16.,  9.,  0.],\n",
       "        ...,\n",
       "        [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "        [ 0.,  0.,  2., ..., 12.,  0.,  0.],\n",
       "        [ 0.,  0., 10., ..., 12.,  1.,  0.]]),\n",
       " 'target': array([0, 1, 2, ..., 8, 9, 8]),\n",
       " 'frame': None,\n",
       " 'feature_names': ['pixel_0_0',\n",
       "  'pixel_0_1',\n",
       "  'pixel_0_2',\n",
       "  'pixel_0_3',\n",
       "  'pixel_0_4',\n",
       "  'pixel_0_5',\n",
       "  'pixel_0_6',\n",
       "  'pixel_0_7',\n",
       "  'pixel_1_0',\n",
       "  'pixel_1_1',\n",
       "  'pixel_1_2',\n",
       "  'pixel_1_3',\n",
       "  'pixel_1_4',\n",
       "  'pixel_1_5',\n",
       "  'pixel_1_6',\n",
       "  'pixel_1_7',\n",
       "  'pixel_2_0',\n",
       "  'pixel_2_1',\n",
       "  'pixel_2_2',\n",
       "  'pixel_2_3',\n",
       "  'pixel_2_4',\n",
       "  'pixel_2_5',\n",
       "  'pixel_2_6',\n",
       "  'pixel_2_7',\n",
       "  'pixel_3_0',\n",
       "  'pixel_3_1',\n",
       "  'pixel_3_2',\n",
       "  'pixel_3_3',\n",
       "  'pixel_3_4',\n",
       "  'pixel_3_5',\n",
       "  'pixel_3_6',\n",
       "  'pixel_3_7',\n",
       "  'pixel_4_0',\n",
       "  'pixel_4_1',\n",
       "  'pixel_4_2',\n",
       "  'pixel_4_3',\n",
       "  'pixel_4_4',\n",
       "  'pixel_4_5',\n",
       "  'pixel_4_6',\n",
       "  'pixel_4_7',\n",
       "  'pixel_5_0',\n",
       "  'pixel_5_1',\n",
       "  'pixel_5_2',\n",
       "  'pixel_5_3',\n",
       "  'pixel_5_4',\n",
       "  'pixel_5_5',\n",
       "  'pixel_5_6',\n",
       "  'pixel_5_7',\n",
       "  'pixel_6_0',\n",
       "  'pixel_6_1',\n",
       "  'pixel_6_2',\n",
       "  'pixel_6_3',\n",
       "  'pixel_6_4',\n",
       "  'pixel_6_5',\n",
       "  'pixel_6_6',\n",
       "  'pixel_6_7',\n",
       "  'pixel_7_0',\n",
       "  'pixel_7_1',\n",
       "  'pixel_7_2',\n",
       "  'pixel_7_3',\n",
       "  'pixel_7_4',\n",
       "  'pixel_7_5',\n",
       "  'pixel_7_6',\n",
       "  'pixel_7_7'],\n",
       " 'target_names': array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]),\n",
       " 'images': array([[[ 0.,  0.,  5., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  0., 13., ..., 15.,  5.,  0.],\n",
       "         [ 0.,  3., 15., ..., 11.,  8.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  4., 11., ..., 12.,  7.,  0.],\n",
       "         [ 0.,  2., 14., ..., 12.,  0.,  0.],\n",
       "         [ 0.,  0.,  6., ...,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0., ...,  5.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  9.,  0.,  0.],\n",
       "         [ 0.,  0.,  3., ...,  6.,  0.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "         [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ..., 10.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0., ..., 12.,  0.,  0.],\n",
       "         [ 0.,  0.,  3., ..., 14.,  0.,  0.],\n",
       "         [ 0.,  0.,  8., ..., 16.,  0.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  9., 16., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  3., 13., ..., 11.,  5.,  0.],\n",
       "         [ 0.,  0.,  0., ..., 16.,  9.,  0.]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0.,  0.,  1., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  0., 13., ...,  2.,  1.,  0.],\n",
       "         [ 0.,  0., 16., ..., 16.,  5.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  0., 16., ..., 15.,  0.,  0.],\n",
       "         [ 0.,  0., 15., ..., 16.,  0.,  0.],\n",
       "         [ 0.,  0.,  2., ...,  6.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  2., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0., 14., ..., 15.,  1.,  0.],\n",
       "         [ 0.,  4., 16., ..., 16.,  7.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  0.,  0., ..., 16.,  2.,  0.],\n",
       "         [ 0.,  0.,  4., ..., 16.,  2.,  0.],\n",
       "         [ 0.,  0.,  5., ..., 12.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0., 10., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  2., 16., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  0., 15., ..., 15.,  0.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  4., 16., ..., 16.,  6.,  0.],\n",
       "         [ 0.,  8., 16., ..., 16.,  8.,  0.],\n",
       "         [ 0.,  1.,  8., ..., 12.,  1.,  0.]]]),\n",
       " 'DESCR': \".. _digits_dataset:\\n\\nOptical recognition of handwritten digits dataset\\n--------------------------------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 5620\\n    :Number of Attributes: 64\\n    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\\n    :Missing Attribute Values: None\\n    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\\n    :Date: July; 1998\\n\\nThis is a copy of the test set of the UCI ML hand-written digits datasets\\nhttps://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\\n\\nThe data set contains images of hand-written digits: 10 classes where\\neach class refers to a digit.\\n\\nPreprocessing programs made available by NIST were used to extract\\nnormalized bitmaps of handwritten digits from a preprinted form. From a\\ntotal of 43 people, 30 contributed to the training set and different 13\\nto the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\\n4x4 and the number of on pixels are counted in each block. This generates\\nan input matrix of 8x8 where each element is an integer in the range\\n0..16. This reduces dimensionality and gives invariance to small\\ndistortions.\\n\\nFor info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\\nT. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\\nL. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\\n1994.\\n\\n.. topic:: References\\n\\n  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\\n    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\\n    Graduate Studies in Science and Engineering, Bogazici University.\\n  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\\n  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\\n    Linear dimensionalityreduction using relevance weighted LDA. School of\\n    Electrical and Electronic Engineering Nanyang Technological University.\\n    2005.\\n  - Claudio Gentile. A New Approximate Maximal Margin Classification\\n    Algorithm. NIPS. 2000.\"}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DESCR', 'data', 'feature_names', 'frame', 'images', 'target', 'target_names']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797, 8, 8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Il y a 1797 classe dans data.target = [0 1 2 ... 8 9 8]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Il y a {len(data.target)} classe dans data.target = {data.target}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  5. 13.  9.  1.  0.  0.]\n",
      " [ 0.  0. 13. 15. 10. 15.  5.  0.]\n",
      " [ 0.  3. 15.  2.  0. 11.  8.  0.]\n",
      " [ 0.  4. 12.  0.  0.  8.  8.  0.]\n",
      " [ 0.  5.  8.  0.  0.  9.  8.  0.]\n",
      " [ 0.  4. 11.  0.  1. 12.  7.  0.]\n",
      " [ 0.  2. 14.  5. 10. 12.  0.  0.]\n",
      " [ 0.  0.  6. 13. 10.  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "print(data.images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.target[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 12 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_digits(start):    \n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    cmap = matplotlib.colors.ListedColormap(['red', 'black'])\n",
    "    for im in range(12):\n",
    "        plt.subplot(3,4,im+1)\n",
    "        title = str(start+im) + \":\" + str(data.target[start+im])\n",
    "        plt.title(title)\n",
    "        plt.imshow(data.images[start+im], cmap=cmap)     \n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "plot_digits(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797, 64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = data.target\n",
    "x = data.images.reshape((len(data.images), -1))\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_test, y_test  = x[:1347], y[:1347], x[1347:], y[1347:]\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_classifier = MLPClassifier(hidden_layer_sizes=(20,), activation='logistic',\n",
    "                    solver='sgd', tol=0.01, n_iter_no_change=30, random_state=1, alpha=0.0001, learning_rate_init=.1, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 2.11541077\n",
      "Iteration 2, loss = 1.57554613\n",
      "Iteration 3, loss = 1.09801886\n",
      "Iteration 4, loss = 0.73154274\n",
      "Iteration 5, loss = 0.50055650\n",
      "Iteration 6, loss = 0.35982359\n",
      "Iteration 7, loss = 0.27664221\n",
      "Iteration 8, loss = 0.22433407\n",
      "Iteration 9, loss = 0.18744375\n",
      "Iteration 10, loss = 0.16000843\n",
      "Iteration 11, loss = 0.14162545\n",
      "Iteration 12, loss = 0.12927647\n",
      "Iteration 13, loss = 0.11615470\n",
      "Iteration 14, loss = 0.10479092\n",
      "Iteration 15, loss = 0.09712149\n",
      "Iteration 16, loss = 0.09136116\n",
      "Iteration 17, loss = 0.08460672\n",
      "Iteration 18, loss = 0.07779865\n",
      "Iteration 19, loss = 0.07367984\n",
      "Iteration 20, loss = 0.06950367\n",
      "Iteration 21, loss = 0.06492229\n",
      "Iteration 22, loss = 0.06197923\n",
      "Iteration 23, loss = 0.05831109\n",
      "Iteration 24, loss = 0.05514949\n",
      "Iteration 25, loss = 0.05270835\n",
      "Iteration 26, loss = 0.05078068\n",
      "Iteration 27, loss = 0.04873687\n",
      "Iteration 28, loss = 0.04666945\n",
      "Iteration 29, loss = 0.04455524\n",
      "Iteration 30, loss = 0.04335551\n",
      "Iteration 31, loss = 0.04077589\n",
      "Iteration 32, loss = 0.04042720\n",
      "Iteration 33, loss = 0.03840081\n",
      "Iteration 34, loss = 0.03712750\n",
      "Iteration 35, loss = 0.03541682\n",
      "Iteration 36, loss = 0.03454883\n",
      "Iteration 37, loss = 0.03351287\n",
      "Iteration 38, loss = 0.03211557\n",
      "Iteration 39, loss = 0.03125520\n",
      "Iteration 40, loss = 0.03055659\n",
      "Iteration 41, loss = 0.02953468\n",
      "Iteration 42, loss = 0.02861324\n",
      "Iteration 43, loss = 0.02787232\n",
      "Iteration 44, loss = 0.02729019\n",
      "Iteration 45, loss = 0.02653771\n",
      "Training loss did not improve more than tol=0.010000 for 30 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='logistic', hidden_layer_sizes=(20,),\n",
       "              learning_rate_init=0.1, n_iter_no_change=30, random_state=1,\n",
       "              solver='sgd', tol=0.01, verbose=True)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_classifier.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.neural_network._multilayer_perceptron.MLPClassifier"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(mlp_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = mlp_classifier.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9222222222222223"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "accuracy_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     y_test[10:20] = [1 5 0 9 5 2 8 2 0 0]\n",
      "predictions[10:20] = [1 5 0 9 6 2 8 2 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(f\"     y_test[10:20] = {y_test[10:20]}\")\n",
    "print(f\"predictions[10:20] = {predictions[10:20]}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
